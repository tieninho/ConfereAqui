import streamlit as st
import google.generativeai as genai
from PIL import Image
import io
import os

system_instruction = "Voc√™ √© um modelo de linguagem projetado para detectar desinforma√ß√£o. Analise o seguinte texto de not√≠cias, forne√ßa uma pontua√ß√£o de desinforma√ß√£o de 0 a 1, onde 1 √© altamente prov√°vel de ser desinforma√ß√£o e adicione evid√™ncias de apoio."

# Configura√ß√£o do SDK com as configura√ß√µes de seguran√ßa
GOOGLE_API_KEY = "AIzaSyA5oYJp9yMKID2lBqo9gdkIbpX23IIsGhw"
genai.configure(api_key=GOOGLE_API_KEY)
safety_settings = {
        "HARASSMENT" : "BLOCK_NONE",
        "HATE" : "BLOCK_NONE",
        "SEXUAL" : "BLOCK_NONE",
        "DANGEROUS" : "BLOCK_NONE",
    }

# Configurando a p√°gina
st.set_page_config(page_title='ConfereAqui', page_icon='üîç', layout='wide')

# Fazendo o display do t√≠tulo da p√°gina
st.title('Confere Aqui üîç')

# Texto de introdu√ß√£o e instru√ß√£o de utiliza√ß√£o
st.markdown("""
    Bem-vindo ao Confere Aqui!\n Sou projetado para verificar a veracidade de not√≠cias.\n 
    \n Voc√™ pode fazer upload de uma imagem ou inserir o texto de uma not√≠cia para verificar se h√° desinforma√ß√£o.
    \n Ap√≥s fazer o upload ou inserir o texto, clique no bot√£o "Verificar Not√≠cia" para obter uma an√°lise.
""")

# Inicializando o modelo
system_instruction = "Voc√™ √© um modelo de linguagem projetado para detectar desinforma√ß√£o. Analise o seguinte texto de not√≠cias, forne√ßa uma pontua√ß√£o de desinforma√ß√£o de 0 a 1, onde 1 √© altamente prov√°vel de ser desinforma√ß√£o e adicione evid√™ncias de apoio."
model = genai.GenerativeModel(
    model_name="gemini-1.5-pro-latest",
    system_instruction=system_instruction
)

# Inicializa√ß√£o do estado
if "historico_respostas" not in st.session_state:
    st.session_state.historico_respostas = []

if "resposta_counter" not in st.session_state:
    st.session_state.resposta_counter = 0

# Widget para upload de imagens
upload_button = st.file_uploader("Fa√ßa upload de uma imagem" )
text_input = st.text_area("Ou insira o texto da sua not√≠cia aqui")

# Mensagem de "Gerando resposta..."
gerando_resposta_msg = st.empty()

# Fun√ß√£o para lidar com o clique no bot√£o "Verificar Not√≠cia"
if st.button("Verificar Not√≠cia"):
    content = None
    if upload_button is not None:
        img = Image.open(upload_button)
        content = img
    elif text_input:
        content = text_input

    if content:
        # Exibir a mensagem "Gerando resposta..."
        gerando_resposta_msg.text("Gerando resposta...")

        st.session_state.resposta_counter += 1
        # Gerar o conte√∫do com o modelo de vis√£o do Gemini
        model_vision = genai.GenerativeModel('gemini-1.5-pro-latest')
        response = model_vision.generate_content(["Voc√™ √© um modelo de linguagem projetado para detectar desinforma√ß√£o. Analise o seguinte texto de not√≠cias, forne√ßa uma pontua√ß√£o de desinforma√ß√£o de 0 a 1, onde 1 √© altamente prov√°vel de ser desinforma√ß√£o e adicione evid√™ncias de apoio.", content], stream=True)

        # Resolver a resposta
        response.resolve()

        # Imprimir o texto gerado pelo modelo com a classifica√ß√£o da resposta
        resposta_texto = f"**Resposta {st.session_state.resposta_counter}:** {response.text}"

        # Adicionar a resposta ao hist√≥rico
        st.session_state.historico_respostas.append(resposta_texto)

        # Limpar o campo de texto
        text_input = ""  # Define o campo de texto como vazio

        # Esconder a mensagem "Gerando resposta..."
        gerando_resposta_msg.empty()
            
# Exibir hist√≥rico de respostas em formato de chat
if st.session_state.historico_respostas:
    for i, resposta in enumerate(st.session_state.historico_respostas):
        if i % 2 == 0:
            # Exibe a mensagem enviada pelo usu√°rio
            with st.beta_container():
                st.markdown(f"**Usu√°rio:** {user_query}")
        else:
            # Exibe a resposta do assistente
            with st.beta_container():
                st.markdown(f"**Assistente:** {resposta}")


